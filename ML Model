# Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.datasets import make_classification, make_regression, make_blobs
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import accuracy_score, mean_squared_error, silhouette_score
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Generate synthetic data for classification
def generate_classification_data():
    X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=5, random_state=42)
    return X, y

# Generate synthetic data for regression
def generate_regression_data():
    X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)
    return X, y

# Generate synthetic data for clustering
def generate_clustering_data():
    X, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)
    return X

# Function to perform classification with hyperparameter tuning
def classification_model(X_train, y_train):
    clf = RandomForestClassifier(random_state=42)
    param_grid = {
        'n_estimators': [50, 100],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5]
    }
    
    grid_search = GridSearchCV(clf, param_grid, cv=5)
    grid_search.fit(X_train, y_train)
    
    print("Best parameters for classification:", grid_search.best_params_)
    
    return grid_search.best_estimator_

# Function to perform regression with hyperparameter tuning
def regression_model(X_train, y_train):
    reg = RandomForestRegressor(random_state=42)
    param_grid = {
        'n_estimators': [50, 100],
        'max_depth': [None, 10, 20],
        'min_samples_split': [2, 5]
    }
    
    grid_search = GridSearchCV(reg, param_grid, cv=5)
    grid_search.fit(X_train, y_train)
    
    print("Best parameters for regression:", grid_search.best_params_)
    
    return grid_search.best_estimator_

# Function to perform clustering and evaluate using silhouette score
def clustering_model(X):
    kmeans = KMeans(n_clusters=4)
    kmeans.fit(X)
    
    silhouette_avg = silhouette_score(X, kmeans.labels_)
    print("Silhouette Score for KMeans Clustering:", silhouette_avg)

    # Plotting the clusters
    plt.scatter(X[:, 0], X[:, 1], c=kmeans.labels_, s=50)
    plt.title("KMeans Clustering")
    plt.xlabel("Feature 1")
    plt.ylabel("Feature 2")
    plt.show()

# Main function to execute the models
def main():
    # Classification Example
    print("Classification Example:")
    X_classification, y_classification = generate_classification_data()
    X_train_classification, X_test_classification, y_train_classification, y_test_classification = train_test_split(
        X_classification, y_classification, test_size=0.2, random_state=42)
    
    clf_model = classification_model(X_train_classification, y_train_classification)
    
    # Evaluate classification model
    y_pred_classification = clf_model.predict(X_test_classification)
    accuracy = accuracy_score(y_test_classification, y_pred_classification)
    print(f"Classification Accuracy: {accuracy:.2f}\n")

    
    # Regression Example
    print("Regression Example:")
    X_regression, y_regression = generate_regression_data()
    X_train_regression, X_test_regression, y_train_regression, y_test_regression = train_test_split(
        X_regression, y_regression, test_size=0.2, random_state=42)

    reg_model = regression_model(X_train_regression, y_train_regression)

    # Evaluate regression model
    y_pred_regression = reg_model.predict(X_test_regression)
    mse = mean_squared_error(y_test_regression, y_pred_regression)
    print(f"Regression Mean Squared Error: {mse:.2f}\n")

    
    # Clustering Example
    print("Clustering Example:")
    X_clustering = generate_clustering_data()
    
    clustering_model(X_clustering)

if __name__ == "__main__":
    main()
